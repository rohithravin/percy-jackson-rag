# Building a RAG + LLM using Percy Jackson Books

## Background
Recent advancements in artificial intelligence, particularly in language models and retrieval-augmented generation (RAG), have opened new avenues for creating sophisticated applications. This project aims to leverage these technologies to create a powerful question-answering system using the world of Percy Jackson books. The system will use LangChain for orchestration, a Vector Database (Vector DB) for embeddings and retrieval, and the Ollama API with Llama3 for language modeling. Additionally, we will compare the performance and quality of responses and embeddings using two different retrieval mechanisms: ElasticSearch and a Vector Database.

## Objectives
- Create a RAG + LLM system that can answer questions based on the content of Percy Jackson books.

- Implement and integrate LangChain, Vector DB, and Ollama (using Llama3).

- Compare the performance of the system using ElasticSearch and Vector DB for document retrieval and embedding generation.

- Evaluate the quality of responses and embeddings from both ElasticSearch and Vector DB to determine the most effective setup.